{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace525df-c48b-4a87-8ceb-2bada060caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2  # opencv+python == 4.9.0.80 # image processing\n",
    "import matplotlib.pyplot as plt\n",
    "import hdf5storage  # 0.1.19 # for loading .mat files\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf # Ensure using 2.13.0 as mentioned\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Conv2DTranspose, BatchNormalization, Activation)\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers.legacy import Adam # trying legacy Adam for better performance\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # optional data augmentation\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b10d289-62f8-448b-b0a9-52a6f682d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Mask Flat: [1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Pred Mask Flat: [0.9  0.05 0.05 0.1  0.8  0.1  0.1  0.1  0.8  0.8  0.1  0.1 ]\n",
      "Intersection: 3.3\n",
      "Sum of True Mask: 4.0\n",
      "Sum of Predicted Mask: 4.0\n",
      "Dice Coefficient: 0.84444445\n",
      "True Mask Flat: [1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Pred Mask Flat: [0.9  0.05 0.05 0.1  0.8  0.1  0.1  0.1  0.8  0.8  0.1  0.1 ]\n",
      "Intersection: 3.3\n",
      "Sum of True Mask: 4.0\n",
      "Sum of Predicted Mask: 4.0\n",
      "Dice Coefficient: 0.84444445\n",
      "Dice Coefficient: 0.84444445\n",
      "Dice Loss: 0.15555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:58:58.284527: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-06-02 16:58:58.284549: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-06-02 16:58:58.284555: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-06-02 16:58:58.284638: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-02 16:58:58.284679: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def dice_coef(true_mask, pred_mask, smooth=1.0):\n",
    "    true_mask_flat = tf.keras.backend.flatten(tf.cast(true_mask, 'float32'))\n",
    "    pred_mask_flat = tf.keras.backend.flatten(tf.cast(pred_mask, 'float32'))\n",
    "    \n",
    "    print(\"True Mask Flat:\", true_mask_flat.numpy())\n",
    "    print(\"Pred Mask Flat:\", pred_mask_flat.numpy())\n",
    "    \n",
    "    intersection = tf.reduce_sum(true_mask_flat * pred_mask_flat)\n",
    "    print(\"Intersection:\", intersection.numpy())\n",
    "    \n",
    "    sum_true_mask = tf.reduce_sum(true_mask_flat)\n",
    "    sum_pred_mask = tf.reduce_sum(pred_mask_flat)\n",
    "    \n",
    "    print(\"Sum of True Mask:\", sum_true_mask.numpy())\n",
    "    print(\"Sum of Predicted Mask:\", sum_pred_mask.numpy())\n",
    "    \n",
    "    dice_coef = (2. * intersection + smooth) / (sum_true_mask + sum_pred_mask + smooth)\n",
    "    print(\"Dice Coefficient:\", dice_coef.numpy())\n",
    "    return dice_coef\n",
    "\n",
    "def dice_loss(true_mask, pred_mask):\n",
    "    return 1 - dice_coef(true_mask, pred_mask)\n",
    "\n",
    "# Sample data\n",
    "true_mask = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1], [1, 0, 0]]])\n",
    "pred_mask = np.array([[[0.9, 0.05, 0.05], [0.1, 0.8, 0.1]], [[0.1, 0.1, 0.8], [0.8, 0.1, 0.1]]])\n",
    "\n",
    "true_mask = tf.convert_to_tensor(true_mask, dtype=tf.float32)\n",
    "pred_mask = tf.convert_to_tensor(pred_mask, dtype=tf.float32)\n",
    "\n",
    "# Calculate Dice Coefficient and Dice Loss\n",
    "dice_coefficient = dice_coef(true_mask, pred_mask)\n",
    "dice_loss_value = dice_loss(true_mask, pred_mask)\n",
    "\n",
    "print(\"Dice Coefficient:\", dice_coefficient.numpy())\n",
    "print(\"Dice Loss:\", dice_loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a5cc12-0c57-40a8-8070-2e5e89a286e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Mask Flat: [1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Pred Mask Flat: [0.9  0.05 0.05 0.1  0.8  0.1  0.1  0.1  0.8  0.8  0.1  0.1 ]\n",
      "Intersection: 3.3\n",
      "Sum of True Mask: 4.0\n",
      "Sum of Predicted Mask: 4.0\n",
      "Union: 4.7\n",
      "IoU Coefficient: 0.754386\n",
      "True Mask Flat: [1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Pred Mask Flat: [0.9  0.05 0.05 0.1  0.8  0.1  0.1  0.1  0.8  0.8  0.1  0.1 ]\n",
      "Intersection: 3.3\n",
      "Sum of True Mask: 4.0\n",
      "Sum of Predicted Mask: 4.0\n",
      "Union: 4.7\n",
      "IoU Coefficient: 0.754386\n",
      "IoU Coefficient: 0.754386\n",
      "Jaccard Loss: 0.24561399\n"
     ]
    }
   ],
   "source": [
    "def iou_coef(true_mask, pred_mask, smooth=1):\n",
    "    true_mask_flat = tf.keras.backend.flatten(tf.cast(true_mask, 'float32'))\n",
    "    pred_mask_flat = tf.keras.backend.flatten(tf.cast(pred_mask, 'float32'))\n",
    "    \n",
    "    print(\"True Mask Flat:\", true_mask_flat.numpy())\n",
    "    print(\"Pred Mask Flat:\", pred_mask_flat.numpy())\n",
    "    \n",
    "    intersection = tf.reduce_sum(true_mask_flat * pred_mask_flat)\n",
    "    print(\"Intersection:\", intersection.numpy())\n",
    "    \n",
    "    sum_true_mask = tf.reduce_sum(true_mask_flat)\n",
    "    sum_pred_mask = tf.reduce_sum(pred_mask_flat)\n",
    "    \n",
    "    print(\"Sum of True Mask:\", sum_true_mask.numpy())\n",
    "    print(\"Sum of Predicted Mask:\", sum_pred_mask.numpy())\n",
    "    \n",
    "    union = sum_true_mask + sum_pred_mask - intersection\n",
    "    print(\"Union:\", union.numpy())\n",
    "    \n",
    "    iou_coef = (intersection + smooth) / (union + smooth)\n",
    "    print(\"IoU Coefficient:\", iou_coef.numpy())\n",
    "    return iou_coef\n",
    "\n",
    "def jaccard_loss(true_mask, pred_mask, smooth=1):\n",
    "    iou_coef_value = iou_coef(true_mask, pred_mask, smooth)\n",
    "    return 1 - iou_coef_value\n",
    "\n",
    "# Sample data\n",
    "true_mask = np.array([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1], [1, 0, 0]]])\n",
    "pred_mask = np.array([[[0.9, 0.05, 0.05], [0.1, 0.8, 0.1]], [[0.1, 0.1, 0.8], [0.8, 0.1, 0.1]]])\n",
    "\n",
    "true_mask = tf.convert_to_tensor(true_mask, dtype=tf.float32)\n",
    "pred_mask = tf.convert_to_tensor(pred_mask, dtype=tf.float32)\n",
    "\n",
    "# Calculate IoU Coefficient and Jaccard Loss\n",
    "iou_coefficient = iou_coef(true_mask, pred_mask)\n",
    "jaccard_loss_value = jaccard_loss(true_mask, pred_mask)\n",
    "\n",
    "print(\"IoU Coefficient:\", iou_coefficient.numpy())\n",
    "print(\"Jaccard Loss:\", jaccard_loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc36b9f-fdaf-4499-8cfa-1b0510c3747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "True Mask Class:\n",
      " [[[[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]]]]\n",
      "Pred Mask Class:\n",
      " [[[[[1. 0. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]]\n",
      "\n",
      "\n",
      "  [[[0. 1. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]]\n",
      "\n",
      "\n",
      "  [[[1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 1.]]\n",
      "\n",
      "   [[1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]\n",
      "\n",
      "   [[1. 0. 0.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[1. 0. 0.]]\n",
      "\n",
      "   [[1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]\n",
      "\n",
      "   [[0. 0. 1.]]]\n",
      "\n",
      "\n",
      "  [[[0. 1. 0.]]\n",
      "\n",
      "   [[1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 1.]]\n",
      "\n",
      "   [[0. 0. 1.]]]\n",
      "\n",
      "\n",
      "  [[[1. 0. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[1. 0. 0.]]]\n",
      "\n",
      "\n",
      "  [[[1. 0. 0.]]\n",
      "\n",
      "   [[1. 0. 0.]]\n",
      "\n",
      "   [[0. 1. 0.]]\n",
      "\n",
      "   [[1. 0. 0.]]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (2, 4, 4, 1) and (2, 4, 4, 1, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m pred_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(pred_mask, depth\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Test the function\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m mean_loss, class_losses \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_loss\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mcalculate_losses\u001b[0;34m(true_mask, pred_mask, num_classes, weight_ce, weight_dice)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred Mask Class:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, pred_mask_class\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate categorical cross-entropy (CE) loss\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_mask_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_mask_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCE Loss:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, ce_loss\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate Dice loss\u001b[39;00m\n",
      "File \u001b[0;32m~/UNETENV/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/UNETENV/lib/python3.11/site-packages/keras/src/losses.py:2122\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   2115\u001b[0m         label_smoothing \u001b[38;5;241m/\u001b[39m num_classes\n\u001b[1;32m   2116\u001b[0m     )\n\u001b[1;32m   2118\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m   2119\u001b[0m     label_smoothing, _smooth_labels, \u001b[38;5;28;01mlambda\u001b[39;00m: y_true\n\u001b[1;32m   2120\u001b[0m )\n\u001b[0;32m-> 2122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UNETENV/lib/python3.11/site-packages/keras/src/backend.py:5560\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5558\u001b[0m target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(target)\n\u001b[1;32m   5559\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m-> 5560\u001b[0m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5562\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m   5563\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5564\u001b[0m )\n\u001b[1;32m   5565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (2, 4, 4, 1) and (2, 4, 4, 1, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "# Calculate loss per class and mean loss with print statements for debugging\n",
    "def calculate_losses(true_mask, pred_mask, num_classes=3, weight_ce=0.1, weight_dice=0.9):\n",
    "    class_losses = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        # Extract class-specific masks\n",
    "        true_mask_class = tf.cast(tf.equal(tf.argmax(true_mask, axis=-1), i), tf.float32)\n",
    "        pred_mask_class = tf.one_hot(tf.argmax(pred_mask, axis=-1), depth=true_mask.shape[-1])\n",
    "        \n",
    "        print(f\"Class {i}:\")\n",
    "        print(\"True Mask Class:\\n\", true_mask_class.numpy())\n",
    "        print(\"Pred Mask Class:\\n\", pred_mask_class.numpy())\n",
    "        \n",
    "        # Calculate categorical cross-entropy (CE) loss\n",
    "        ce_loss = tf.keras.losses.categorical_crossentropy(true_mask_class, pred_mask_class)\n",
    "        print(\"CE Loss:\\n\", ce_loss.numpy())\n",
    "        \n",
    "        # Calculate Dice loss\n",
    "        dice_loss_val = dice_loss(true_mask_class, pred_mask_class)\n",
    "        print(\"Dice Loss:\\n\", dice_loss_val.numpy())\n",
    "        \n",
    "        # Combine losses\n",
    "        combined_loss_val = weight_ce * ce_loss + weight_dice * dice_loss_val\n",
    "        class_loss = tf.reduce_mean(combined_loss_val)\n",
    "        \n",
    "        print(\"Combined Loss Value:\\n\", combined_loss_val.numpy())\n",
    "        print(\"Class Loss:\\n\", class_loss.numpy())\n",
    "        \n",
    "        class_losses.append(class_loss)\n",
    "    \n",
    "    # Calculate mean loss across all classes\n",
    "    mean_loss = tf.reduce_mean(tf.stack(class_losses), axis=0)\n",
    "    print(\"Mean Loss:\\n\", mean_loss.numpy())\n",
    "    return mean_loss, class_losses\n",
    "\n",
    "# Create sample true and predicted masks\n",
    "batch_size = 2\n",
    "height = 4\n",
    "width = 4\n",
    "num_classes = 3\n",
    "\n",
    "true_mask = np.random.randint(0, num_classes, size=(batch_size, height, width, 1))\n",
    "pred_mask = np.random.randint(0, num_classes, size=(batch_size, height, width, 1))\n",
    "\n",
    "true_mask = tf.one_hot(true_mask, depth=num_classes)\n",
    "pred_mask = tf.one_hot(pred_mask, depth=num_classes)\n",
    "\n",
    "# Test the function\n",
    "mean_loss, class_losses = calculate_losses(true_mask, pred_mask, num_classes=num_classes)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(\"Mean Loss:\", mean_loss.numpy())\n",
    "print(\"Class Losses:\", [loss.numpy() for loss in class_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c9a969-3417-4f03-9b97-54829a491686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class ID: 0\n",
      "True mask class (first sample): \n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Predicted mask class (first sample): \n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Correct predictions: 3.0\n",
      "Total predictions: 3.0\n",
      "Accuracy for class 0: 1.0\n",
      "\n",
      "Class ID: 1\n",
      "True mask class (first sample): \n",
      "[[0. 1. 0.]\n",
      " [1. 1. 0.]]\n",
      "Predicted mask class (first sample): \n",
      "[[0. 1. 1.]\n",
      " [1. 1. 0.]]\n",
      "Correct predictions: 4.0\n",
      "Total predictions: 5.0\n",
      "Accuracy for class 1: 0.800000011920929\n",
      "\n",
      "Class ID: 2\n",
      "True mask class (first sample): \n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Predicted mask class (first sample): \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "Correct predictions: 2.0\n",
      "Total predictions: 4.0\n",
      "Accuracy for class 2: 0.5\n",
      "\n",
      "Mean Accuracy: 0.7666666507720947\n",
      "\n",
      "Final Accuracies:\n",
      "Mean Accuracy: 0.7666666507720947\n",
      "Accuracy for Class 0: 1.0\n",
      "Accuracy for Class 1: 0.800000011920929\n",
      "Accuracy for Class 2: 0.5\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracies(true_mask, pred_mask, num_classes=3):\n",
    "    class_accuracies = []\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        print(f\"\\nClass ID: {class_id}\")\n",
    "        true_mask_class = tf.cast(tf.equal(tf.argmax(true_mask, axis=-1), class_id), tf.float32)\n",
    "        pred_class = tf.argmax(pred_mask, axis=-1)\n",
    "        pred_mask_class = tf.cast(tf.equal(pred_class, class_id), tf.float32)\n",
    "        \n",
    "        print(f\"True mask class (first sample): \\n{true_mask_class.numpy()[0]}\")\n",
    "        print(f\"Predicted mask class (first sample): \\n{pred_mask_class.numpy()[0]}\")\n",
    "        \n",
    "        correct_predictions = tf.reduce_sum(tf.cast(tf.equal(true_mask_class, pred_mask_class), tf.float32) * true_mask_class)\n",
    "        total_predictions = tf.reduce_sum(true_mask_class)\n",
    "        accuracy = correct_predictions / (total_predictions + tf.keras.backend.epsilon())\n",
    "        \n",
    "        print(f\"Correct predictions: {correct_predictions.numpy()}\")\n",
    "        print(f\"Total predictions: {total_predictions.numpy()}\")\n",
    "        print(f\"Accuracy for class {class_id}: {accuracy.numpy()}\")\n",
    "        \n",
    "        class_accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = tf.reduce_mean(tf.stack(class_accuracies), axis=0)\n",
    "    print(f\"\\nMean Accuracy: {mean_accuracy.numpy()}\")\n",
    "    \n",
    "    return mean_accuracy, class_accuracies\n",
    "\n",
    "# sample set\n",
    "true_mask_sample = np.array([\n",
    "    [[0, 1, 2], [1, 1, 2]],\n",
    "    [[2, 2, 0], [0, 1, 1]]\n",
    "])\n",
    "pred_mask_sample = np.array([\n",
    "    [[0, 1, 1], [1, 1, 2]],\n",
    "    [[2, 0, 0], [0, 1, 2]]\n",
    "])\n",
    "\n",
    "# one-hot encode the true masks for simplicity\n",
    "true_mask_one_hot = tf.one_hot(true_mask_sample, depth=3)\n",
    "pred_mask_one_hot = tf.one_hot(pred_mask_sample, depth=3)\n",
    "\n",
    "# test on sample dataset\n",
    "mean_acc, class_accs = calculate_accuracies(true_mask_one_hot, pred_mask_one_hot, num_classes=3)\n",
    "\n",
    "print(\"\\nFinal Accuracies:\")\n",
    "print(f\"Mean Accuracy: {mean_acc.numpy()}\")\n",
    "for i, acc in enumerate(class_accs):\n",
    "    print(f\"Accuracy for Class {i}: {acc.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UNETENV)",
   "language": "python",
   "name": "unetenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
